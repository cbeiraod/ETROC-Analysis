{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import beamtest_analysis_helper as helper\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import mplhep as hep\n",
    "hep.style.use('CMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_read = ['evt', 'board', 'row', 'col', 'toa', 'tot', 'cal']\n",
    "names = [\"ET2_EPIR_Pair1\", \"ET2p01_BAR_4\", \"ET2p01_BAR_5\", \"ET2_EPIR_Pair4\"]\n",
    "\n",
    "high_voltages = [250, 260, 210, 260]\n",
    "offsets = [15, 10, 10, 15]\n",
    "\n",
    "chip_figtitles = [\n",
    "    f\"(Trigger) EPIR Pair1 HV{high_voltages[0]}V OS:{offsets[0]}\",\n",
    "    f\"(DUT1) Barcelona 4 HV{high_voltages[1]}V OS:{offsets[1]}\",\n",
    "    f\"(Reference) Barcelona 5 HV{high_voltages[2]}V OS:{offsets[2]}\",\n",
    "    f\"(DUT2) EPIR Pair4 HV{high_voltages[3]}V OS:{offsets[3]}\"\n",
    "]\n",
    "\n",
    "dut1_id = 1\n",
    "dut2_id = 2\n",
    "ref_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = natsorted(glob('DESYFeb2024_Run_34_feather/*feather'))\n",
    "files[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframe based on single pixel selection from the trigger board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_evt = 0\n",
    "dataframes = []\n",
    "\n",
    "for idx, ifile in enumerate(tqdm(files)):\n",
    "\n",
    "    tmp_df = pd.read_feather(ifile, columns=columns_to_read)\n",
    "\n",
    "    if tmp_df.empty:\n",
    "        continue\n",
    "\n",
    "    trig_df = tmp_df[(tmp_df['board'] == 0) & (tmp_df['row'] == 7) & (tmp_df['col'] == 4)]\n",
    "    other_df = tmp_df[tmp_df['evt'].isin(trig_df['evt']) & (tmp_df['board'] != 0)]\n",
    "\n",
    "    subset_df = pd.concat([trig_df, other_df])\n",
    "    subset_df = subset_df.sort_values(by=['evt', 'board'])\n",
    "    subset_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    del tmp_df, trig_df, other_df\n",
    "\n",
    "    if subset_df.empty:\n",
    "        continue\n",
    "\n",
    "    subset_df.reset_index(drop=True, inplace=True)\n",
    "    subset_df['evt'] = subset_df.groupby('evt').ngroup().astype('uint64')\n",
    "\n",
    "    if idx > 0:\n",
    "        subset_df['evt'] += np.uint64(last_evt)\n",
    "\n",
    "    last_evt += np.uint64(subset_df['evt'].nunique())\n",
    "\n",
    "    dataframes.append(subset_df)\n",
    "    del subset_df\n",
    "\n",
    "df = pd.concat(dataframes)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "del dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic TDC plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_inclusive = helper.return_hist(df, chipNames=names, chipLabels=[0,1,2,3], hist_bins=[100, 128, 128])\n",
    "\n",
    "for iboard in [0,1,2,3]:\n",
    "    helper.plot_1d_TDC_histograms(h_inclusive, names[iboard], names[iboard], chip_figtitles[iboard], save=False,\n",
    "                                tag=\"inclusive\", fig_tag=\", inclusive\", slide_friendly=True)\n",
    "\n",
    "del h_inclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupancy map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_occupany_map(df, chipLabels=[0,1,2,3], chipNames=names, fig_title=chip_figtitles, fig_tag='inclusive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by TDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting good hits\n",
    "tdc_cuts = {}\n",
    "for idx in [0,1,2,3]:\n",
    "    # board ID: [CAL LB, CAL UB, TOA LB, TOA UB, TOT LB, TOT UB]\n",
    "    if idx == 0:\n",
    "        tdc_cuts[idx] = [df.loc[df['board'] == idx]['cal'].mode()[0]-3, df.loc[df['board'] == idx]['cal'].mode()[0]+3,  400, 500, 100, 250]\n",
    "    elif idx == ref_id:\n",
    "        tdc_cuts[idx] = [df.loc[df['board'] == idx]['cal'].mode()[0]-3, df.loc[df['board'] == idx]['cal'].mode()[0]+3,  0, 1100, 100, 200]\n",
    "    else:\n",
    "        tdc_cuts[idx] = [df.loc[df['board'] == idx]['cal'].mode()[0]-3, df.loc[df['board'] == idx]['cal'].mode()[0]+3,  0, 1100, 0, 600]\n",
    "\n",
    "filtered_df = helper.tdc_event_selection(df, tdc_cuts_dict=tdc_cuts, select_by_hit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_after_tdc = helper.return_hist(filtered_df, chipNames=names, chipLabels=[0,1,2,3], hist_bins=[100, 128, 128])\n",
    "\n",
    "for iboard in [0,1,2,3]:\n",
    "    helper.plot_1d_TDC_histograms(h_after_tdc, names[iboard], names[iboard], chip_figtitles[iboard], save=False,\n",
    "                                tag=\"tdc_Selection\", fig_tag=\", TDC cuts\", slide_friendly=True)\n",
    "\n",
    "del h_after_tdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_occupany_map(filtered_df, chipLabels=[0,1,2,3], chipNames=names, fig_title=chip_figtitles, fig_tag='inclusive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_board_counts = filtered_df.groupby(['evt', 'board']).size().unstack(fill_value=0)\n",
    "event_selection_col = None\n",
    "\n",
    "trig_selection = (event_board_counts[0] == 1)\n",
    "ref_selection = (event_board_counts[ref_id] == 1)\n",
    "event_selection_col = trig_selection & ref_selection\n",
    "\n",
    "case1_df = filtered_df[filtered_df['evt'].isin(event_board_counts[event_selection_col].index)]\n",
    "case1_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_row = abs(case1_df[case1_df['board'] == 0]['row'].values - case1_df[case1_df['board'] == ref_id]['row'].values)\n",
    "diff_col = abs(case1_df[case1_df['board'] == 0]['col'].values - case1_df[case1_df['board'] == ref_id]['col'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select event numbers where trig - ref colinearity has been satisfied\n",
    "trig_ref_colinear_evts = case1_df['evt'].unique()[(diff_row <= 1) & (diff_col <= 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dut1_df = helper.return_broadcast_dataframe(input_df=filtered_df, trig_board_id=0, ref_board_id=ref_id, dut_board_id=dut1_id, trig_dut=True, ref_dut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colinear_dut1_df = dut1_df[dut1_df['evt'].isin(trig_ref_colinear_evts)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Board-level Efficiency of DUT w/ considering colinear of trigger and reference boards\n",
    "100*colinear_dut1_df['evt'].nunique()/trig_ref_colinear_evts.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_row = colinear_dut1_df[colinear_dut1_df['board'] == 0]['row'].values - colinear_dut1_df[colinear_dut1_df['board'] == dut1_id]['row'].values\n",
    "diff_col = colinear_dut1_df[colinear_dut1_df['board'] == 0]['col'].values - colinear_dut1_df[colinear_dut1_df['board'] == dut1_id]['col'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select event numbers where trig - dut colinearity has been satisfied\n",
    "trig_dut_colinear_df = colinear_dut1_df[colinear_dut1_df['board'] == 0][(diff_row <= 2) & (diff_col <= 2)]\n",
    "trig_dut_colinear_evts = trig_dut_colinear_df['evt'].unique()\n",
    "print(trig_dut_colinear_evts.size, colinear_dut1_df['evt'].nunique(), trig_ref_colinear_evts.size, dut1_df['evt'].nunique(), case1_df['evt'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100*trig_dut_colinear_df['evt'].nunique()/case1_df['evt'].nunique()\n",
    "100*trig_dut_colinear_df['evt'].nunique()/trig_ref_colinear_evts.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colinear_case1_df = case1_df[case1_df['evt'].isin(trig_ref_colinear_evts)].reset_index(drop=True)\n",
    "hits_count_by_col_row_board = colinear_case1_df.groupby(['col', 'row', 'board'])['evt'].count().reset_index()\n",
    "hits_count_by_col_row_board = hits_count_by_col_row_board.rename(columns={'evt': 'hits'})\n",
    "denominator = hits_count_by_col_row_board[hits_count_by_col_row_board['board'] == 0].pivot_table(\n",
    "    index='row',\n",
    "    columns='col',\n",
    "    values='hits',\n",
    "    fill_value=0  # Fill missing values with 0 (if any)\n",
    ")\n",
    "\n",
    "if (denominator.shape[0] != 16) or (denominator.shape[1]!= 16):\n",
    "    denominator = denominator.reindex(pd.Index(np.arange(0,16), name='')).reset_index()\n",
    "    denominator = denominator.reindex(columns=np.arange(0,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colinear_case2_df = case1_df[case1_df['evt'].isin(trig_dut_colinear_evts)].reset_index(drop=True)\n",
    "hits_count_by_col_row_board = colinear_case2_df.groupby(['col', 'row', 'board'])['evt'].count().reset_index()\n",
    "hits_count_by_col_row_board = hits_count_by_col_row_board.rename(columns={'evt': 'hits'})\n",
    "numerator = hits_count_by_col_row_board[hits_count_by_col_row_board['board'] == 0].pivot_table(\n",
    "    index='row',\n",
    "    columns='col',\n",
    "    values='hits',\n",
    "    fill_value=0  # Fill missing values with 0 (if any)\n",
    ")\n",
    "\n",
    "if (numerator.shape[0] != 16) or (numerator.shape[1]!= 16):\n",
    "    numerator = numerator.reindex(pd.Index(np.arange(0,16), name='')).reset_index()\n",
    "    numerator = numerator.reindex(columns=np.arange(0,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_table = 100*numerator/denominator\n",
    "eff_table = eff_table.fillna(-1)\n",
    "\n",
    "from matplotlib import colormaps\n",
    "cmap = colormaps['viridis']\n",
    "cmap.set_under(color='lightgrey')\n",
    "\n",
    "# Create a heatmap to visualize the count of hits\n",
    "fig, ax = plt.subplots(dpi=100, figsize=(20, 20))\n",
    "im = ax.imshow(eff_table, cmap=cmap, interpolation=\"nearest\", vmin=0)\n",
    "\n",
    "# Add color bar\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Efficiency', fontsize=20)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "for i in range(16):\n",
    "    for j in range(16):\n",
    "        try:\n",
    "            value = eff_table.iloc[i, j]\n",
    "        except:\n",
    "            value = -1\n",
    "        if value == -1: continue\n",
    "        text_color = 'black' if value > 0.5*(eff_table.values.max() + eff_table.values.min()) else 'white'\n",
    "        text = str(\"{:.1f}%\".format(value))\n",
    "        plt.text(j, i, text, va='center', ha='center', color=text_color, fontsize=17)\n",
    "\n",
    "hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "ax.set_xlabel('Column (col)', fontsize=20)\n",
    "ax.set_ylabel('Row (row)', fontsize=20)\n",
    "ticks = range(0, 16)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_title(f\"Efficiency of DUT projected to the trigger board based on 3-board analysis\", loc=\"right\", size=20)\n",
    "ax.tick_params(axis='x', which='both', length=5, labelsize=17)\n",
    "ax.tick_params(axis='y', which='both', length=5, labelsize=17)\n",
    "ax.invert_xaxis()\n",
    "ax.invert_yaxis()\n",
    "plt.minorticks_off()\n",
    "\n",
    "# fig.savefig('dut1_3board_eff_map.png')\n",
    "# fig.savefig('dut1_3board_eff_map.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOA Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = case1_df.loc[case1_df['board'] == 0]['toa'].reset_index(drop=True)\n",
    "y = case1_df.loc[case1_df['board'] == ref_id]['toa'].reset_index(drop=True)\n",
    "\n",
    "params = np.polyfit(x, y, 1)\n",
    "\n",
    "h_test = hist.Hist(\n",
    "    hist.axis.Regular(128, 0, 1024, name='toa_0', label='toa_0'),\n",
    "    hist.axis.Regular(128, 0, 1024, name=f'toa_{ref_id}', label=f'toa_{ref_id}'),\n",
    ")\n",
    "h_test.fill(x.values, y.values)\n",
    "\n",
    "hep.hist2dplot(h_test, norm=colors.LogNorm())\n",
    "\n",
    "# calculate the trendline\n",
    "trendpoly = np.poly1d(params)\n",
    "\n",
    "# plot the trend line\n",
    "plt.plot(x.values, trendpoly(x.values), 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = (x*params[0] - y + params[1])/(np.sqrt(params[0]**2 + 1))\n",
    "evts = case1_df.loc[case1_df['board'] == 0].reset_index(drop=True)[distance < 3.*np.std(distance)]['evt'].unique()\n",
    "tmp_df = case1_df.loc[case1_df['evt'].isin(evts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tmp_df.loc[tmp_df['board'] == 0]['toa'].reset_index(drop=True)\n",
    "y = tmp_df.loc[tmp_df['board'] == ref_id]['toa'].reset_index(drop=True)\n",
    "\n",
    "params = np.polyfit(x, y, 1)\n",
    "\n",
    "h_test = hist.Hist(\n",
    "    hist.axis.Regular(128, 0, 1024, name='toa_0', label='toa_0'),\n",
    "    hist.axis.Regular(128, 0, 1024, name=f'toa_{ref_id}', label=f'toa_{ref_id}'),\n",
    ")\n",
    "h_test.fill(x.values, y.values)\n",
    "\n",
    "hep.hist2dplot(h_test, norm=colors.LogNorm())\n",
    "\n",
    "# calculate the trendline\n",
    "trendpoly = np.poly1d(params)\n",
    "\n",
    "# plot the trend line\n",
    "plt.plot(x.values, trendpoly(x.values), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = colinear_case2_df[(colinear_case2_df['board']!=2)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['identifier'] = test_df.groupby(['evt', 'board']).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_df = test_df.pivot(index=['evt', 'identifier'], columns=['board'], values=['row', 'col', 'toa', 'tot', 'cal'])\n",
    "test2_df = test2_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = test2_df.groupby(['evt'])['identifier'].sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = test2_df.loc[test2_df['evt'].isin(idx[idx].index)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = defaultdict(list)\n",
    "\n",
    "sum_arr = defaultdict(float)\n",
    "sum_square_arr = defaultdict(float)\n",
    "iteration = 100\n",
    "sampling_fraction = 0.75\n",
    "counter = 0\n",
    "\n",
    "for iloop in tqdm(range(iteration)):\n",
    "\n",
    "    tdc_filtered_df = input_df\n",
    "    board_to_analyze = [0,1,3]\n",
    "\n",
    "    n = int(sampling_fraction*tdc_filtered_df.shape[0])\n",
    "    indices = np.random.choice(tdc_filtered_df['evt'].unique(), n, replace=False)\n",
    "    tdc_filtered_df = tdc_filtered_df.loc[tdc_filtered_df['evt'].isin(indices)]\n",
    "\n",
    "    if tdc_filtered_df.shape[0] < iteration/(3.*(1-sampling_fraction)):\n",
    "        print('Warning!! Sampling size is too small. Skipping this track')\n",
    "        break\n",
    "\n",
    "    d = {\n",
    "        'evt': tdc_filtered_df['evt'].unique(),\n",
    "    }\n",
    "\n",
    "    for idx in board_to_analyze:\n",
    "        bins = 3.125/tdc_filtered_df['cal'][idx].mean()\n",
    "        d[f'toa_b{str(idx)}'] = 12.5 - tdc_filtered_df['toa'][idx] * bins\n",
    "        d[f'tot_b{str(idx)}'] = (2*tdc_filtered_df['tot'][idx] - np.floor(tdc_filtered_df['tot'][idx]/32)) * bins\n",
    "\n",
    "    df_in_time = pd.DataFrame(data=d)\n",
    "    del d, tdc_filtered_df\n",
    "\n",
    "    if(len(board_to_analyze)==3):\n",
    "        corr_toas = helper.three_board_iterative_timewalk_correction(df_in_time, 5, 3, board_list=board_to_analyze)\n",
    "    elif(len(board_to_analyze)==4):\n",
    "        corr_toas = helper.four_board_iterative_timewalk_correction(df_in_time, 5, 3)\n",
    "    else:\n",
    "        print(\"You have less than 3 boards to analyze\")\n",
    "        break\n",
    "\n",
    "    diffs = {}\n",
    "    for board_a in board_to_analyze:\n",
    "        for board_b in board_to_analyze:\n",
    "            if board_b <= board_a:\n",
    "                continue\n",
    "            name = f\"{board_a}{board_b}\"\n",
    "            diffs[name] = np.asarray(corr_toas[f'toa_b{board_a}'] - corr_toas[f'toa_b{board_b}'])\n",
    "    hists = {}\n",
    "    for key in diffs.keys():\n",
    "        hists[key] = hist.Hist(hist.axis.Regular(80, -1.2, 1.2, name=\"TWC_delta_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "        hists[key].fill(diffs[key])\n",
    "\n",
    "    try:\n",
    "        fit_params_lmfit = {}\n",
    "        for key in hists.keys():\n",
    "            params = helper.lmfit_gaussfit_with_pulls(diffs[key], hists[key], std_range_cut=0.4, width_factor=1.25, fig_title='',\n",
    "                                                chipNames='', use_pred_uncert=True, no_show_fit=False, no_draw=True, get_chisqure=False)\n",
    "            fit_params_lmfit[key] = params\n",
    "        del params, hists, diffs, corr_toas\n",
    "\n",
    "        if(len(board_to_analyze)==3):\n",
    "            resolutions = helper.return_resolution_three_board(fit_params_lmfit, var=list(fit_params_lmfit.keys()), board_list=board_to_analyze)\n",
    "        elif(len(board_to_analyze)==4):\n",
    "            resolutions = helper.return_resolution_four_board(fit_params_lmfit)\n",
    "        else:\n",
    "            print(\"You have less than 3 boards to analyze\")\n",
    "            break\n",
    "\n",
    "        if any(np.isnan(val) for key, val in resolutions.items()):\n",
    "            print('fit results is not good, skipping this iteration')\n",
    "            continue\n",
    "\n",
    "        for key in resolutions.keys():\n",
    "            sum_arr[key] += resolutions[key]\n",
    "            sum_square_arr[key] += resolutions[key]**2\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    except Exception as inst:\n",
    "        print(inst)\n",
    "        del hists, diffs, corr_toas\n",
    "\n",
    "if counter != 0:\n",
    "    for idx in board_to_analyze:\n",
    "        final_dict[f'row{idx}'].append(input_df['row'][idx].unique()[0])\n",
    "        final_dict[f'col{idx}'].append(input_df['col'][idx].unique()[0])\n",
    "\n",
    "    for key in sum_arr.keys():\n",
    "        mean = sum_arr[key]/counter\n",
    "        std = np.sqrt((1/(counter-1))*(sum_square_arr[key]-counter*(mean**2)))\n",
    "        final_dict[f'res{key}'].append(mean)\n",
    "        final_dict[f'err{key}'].append(std)\n",
    "else:\n",
    "    print('Track is not validate for bootstrapping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
